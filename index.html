<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/html">

<head>
  <meta charset="utf-8">
  <title>BIAS@ECIR2021 - Second International Workshop on Algorithmic Bias in Search and Recommendation</title>
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta content="" name="keywords">
  <meta content="" name="description">

  <!-- Favicons -->
  <link href="img/favicon.png" rel="icon">
  <link href="img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,700,700i|Raleway:300,400,500,700,800" rel="stylesheet">

  <!-- Bootstrap CSS File -->
  <link href="lib/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Libraries CSS Files -->
  <link href="lib/font-awesome/css/font-awesome.min.css" rel="stylesheet">
  <link href="lib/animate/animate.min.css" rel="stylesheet">
  <link href="lib/venobox/venobox.css" rel="stylesheet">
  <link href="lib/owlcarousel/assets/owl.carousel.min.css" rel="stylesheet">

  <!-- Main Stylesheet File -->
  <link href="css/style.css" rel="stylesheet">

</head>

<body>

  <!--==========================
    Header
  ============================-->
  <header id="header">
    <div class="container">

      <div id="logo" class="pull-left">
        <h1><a href="#main">BIAS 2021</a></h1>
      </div>

      <nav id="nav-menu-container">
        <ul class="nav-menu">
          <li><a href="#aims">Aims</a></li>
          <li><a href="#topics">Topics</a></li>
          <li><a href="#dates">Important Dates</a></li>
          <li><a href="#submission">Submission</a></li>
          <li><a href="#keynote">Keynote</a></li>
          <li><a href="#program">Program</a></li>
          <li><a href="#committee">Committee</a></li>
          <li><a href="#attending">Registration</a></li>
          <li><a href="#editions">Editions</a></li>
          <li><a href="#contacts">Contacts</a></li>
        </ul>
      </nav><!-- #nav-menu-container -->
    </div>
  </header><!-- #header -->

  <!--==========================
    Intro Section
  ============================-->
  <section id="intro">
    <div class="intro-container wow fadeIn">
      <h1 class="mb-4 pb-0">Second International Workshop on <br/> Algorithmic Bias in Search and Recommendation (Bias 2021)</h1>
      <p class="mb-4 pb-0">to be held as part of the <u><a href="https://www.ecir2021.eu/" target="_blank">43rd European Conference on Information Retrieval (ECIR 2021)</a></u></p>
      <p class="mb-4 pb-0">April 1, 2021 09:00-16:30 CEST - ONLINE EVENT</p>
    </div>
  </section>

  <main id="main">

    <!--==========================
    Aims and Scope Section
    ============================-->
    <section id="aims" class="wow fadeInUp">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Workshop Aims and Scope</h2>
		  <p>Both <strong>search</strong> and <strong>recommendation</strong> algorithms provide a user with a ranking that aims to match their needs and interests. Despite the (non) personalized perspective characterizing each class of algorithms, both learn patterns from historical data, which conveys biases in terms of <strong>imbalances</strong> and <strong>inequalities</strong>.</p>

		  <p>In most cases, the trained models and, by extension, the final ranking, unfortunately strengthen these biases in the learned patterns. When a bias impacts on human beings as individuals or as groups with certain legally protected characteristics (e.g., race, gender), the inequalities reinforced by search and recommendation algorithms lead to <strong>severe societal consequences</strong> like discrimination and unfairness.</p>

		  <p>Challenges that arise in the real-world applications are focused, among others, on controlling the effects generated by popularity bias to improve the user's perceived quality of the results, supporting consumers and providers with fair rankings, and transparently explaining why a model provides a given (less) biased result. Hence, being able to <strong>detect</strong>, <strong>measure</strong>, <strong>characterize</strong>, and <strong>mitigate</strong> bias while keeping high effectiveness is a prominent and timely challenge.</p>

		  <p>BIAS 2021 will be the ECIR's workshop aimed at collecting new contributions in this emerging field and providing a <strong>common ground</strong> for interested researchers and practitioners. Specifically, BIAS 2021 will be the second edition of this dedicated event at ECIR, coming after a very successful 2020 delivering. Given the growing interest of the community in these topics, we expect that this workshop will be more and more of interest, with a <strong>stronger outcome</strong> and a <strong>wider community dialog</strong>.</p>

        </div>
      </div>

    </section>

    <!--==========================
    Topics Section
    ============================-->
    <section id="topics" class="wow fadeInUp section-with-bg">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Workshop Topics</h2>
          <p>The workshop welcomes contributions in all topics related to algorithmic biasand fairness in search and recommendation, focused (but not limited) to:</p>
          <ul>
            <li><strong>Data Set Collection and Preparation</strong>:
               <ul>
                  <li>Managing imbalances and inequalities within data sets</li>
                  <li>Devising collection pipelines that lead to fair and unbiased data sets</li>
                  <li>Collecting data sets useful for studying potential biased and unfair situations</li>
                  <li>Designing procedures for creating data sets for research on bias and fairness</li>
              </ul>
            </li>
            <li><strong>Countermeasure Design and Development</strong>:
               <ul>
                  <li>Conducting exploratory analysis that uncover biases</li>
                  <li>Designing treatments that mitigate biases (e.g., popularity bias)</li>
                  <li>Devising interpretable search and recommendation models</li>
                  <li>Providing treatment procedures whose outcomes are easily interpretable</li>
                  <li>Balancing inequalities among different groups of users or stakeholders</li>
              </ul>
            </li>
            <li><strong>Evaluation Protocol and Metric Formulation</strong>:
               <ul>
                  <li>Conducting quantitative experimental studies on bias and unfairness</li>
                  <li>Defining objective metrics that consider fairness and/or bias</li>
                  <li>Formulating bias-aware protocols to evaluate existing algorithms</li>
                  <li>Evaluating existing strategies in unexplored domains</li>
				  <li>Comparative studies of existing evaluation protocols and strategies</li>
              </ul>
            </li>
            <li><strong>Case Study Exploration</strong>:
               <ul>
                  <li>E-commerce platforms</li>
                  <li>Educational environments</li>
                  <li>Entertainment websites</li>
                  <li>Healthcare systems</li>
                  <li>Social media</li>
                  <li>News platforms</li>
                  <li>Digital libraries</li>
                  <li>Job portals</li>
                  <li>Dating platforms</li>
              </ul>
            </li>
          </ul>

        </div>
      </div>

    </section>

    <!--==========================
    Important Dates Section
    ============================-->
    <section id="dates" class="wow fadeInUp">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Important Dates</h2>
          <ul>
            <li>Submissions: <del>January 4, 2021</del> <strong><font color="red">January 11, 2021</font></strong></li>
            <li>Notifications: <del>February 8, 2021</del> <strong><font color="red">February 15, 2021</font></strong></li>
            <li>Camera-Ready: <del>March 1, 2021</del> <strong><font color="red">March 15, 2021</font></strong></li>
            <li>Workshop: April 1, 2021 - ONLINE EVENT</li>
          </ul>
          <p>All deadlines are 11:59pm, AoE time (Anywhere on Earth).</p>
        </div>
      </div>

    </section>

    <!--==========================
    Submission Details Section
    ============================-->
    <section id="submission" class="wow fadeInUp section-with-bg">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Submission Details</h2>
          <p>All submissions must be written in English. Authors should consult ECIR <a href="http://irsg.bcs.org/proceedings/ECIR_Draft_Guidelines.pdf" target="_blank">paper guidelines</a> and
             <a href="http://sigir.org/wp-content/uploads/2018/01/p032.pdf" target="_blank"> Fuhr’s guide to avoid common IR evaluation mistakes</a>, for the preparation of their papers. Authors should consult
             <a href="ftp://ftp.springernature.com/cs-proceeding/svproc/guidelines/Springer_Guidelines_for_Authors_of_Proceedings.pdf" target="_blank">Springer’s authors’ guidelines </a> and use their
             proceedings templates, either <a href="ftp://ftp.springernature.com/cs-proceeding/llncs/llncs2e.zip" target="_blank">LaTeX</a> or <a href="ftp://ftp.springernature.com/cs-proceeding/llncs/word/splnproc1703.zip" target="_blank"> Word</a>.
             Papers should be submitted as PDF files to Easychair at <a href="https://easychair.org/conferences/?conf=bias2021" target="_blank">https://easychair.org/conferences/?conf=bias2021</a>.
             Please be aware that at least one author per paper needs to register and attend the workshop to present the work.</p>
          <p>We will consider three different submission types:</p>
          <ul>
            <li><strong>Full papers (12 pages) </strong> should be clearly placed with respect to the state of the art and state the contribution of the proposal
                in the domain of application, even if presenting preliminary results. In particular, research papers should describe the methodology
                in detail, experiments should be repeatable, and a comparison with the existing approaches in the literature should be made. </li>
            <li><strong>Reproducibility papers (12 pages) </strong> should repeat prior experiments using the original source code and datasets to show how, why, and when the methods work or not (replicability papers) or should repeat prior experiments, preferably using the original source code, in new contexts (e.g., different domains and datasets, different evaluation and metrics) to further generalize and validate or not previous work (reproducibility papers).</li>
            <li><strong> Short or position papers (6 pages) </strong> should introduce new point of views in the workshop topics or summarize the experience of a
                group in the field. Practice and experience reports should present in detail real-world scenarios in which search and recommender
                systems are exploited. </li>
          </ul>

          <p>Submissions should not exceed the indicated number of pages, including any diagrams and references. </p>
          <p>The reviewing process will be coordinated by the organizers. Each paper will receive three reviews from the programme committee, according to reviewers' expertise. </p>
          <p>The accepted papers and the material generated during the meeting will be available on the workshop website. The workshop proceedings will be also published <strong>as a Springer's Communications in Computer and Information Science (CCIS) revised post-proceedings volume</strong>, and indexed on Google Scholar, DBLP and Scopus. Authors of selected papers may be invited to submit an extended version in a journal special issue.</p>
	  <p>We expect authors, PC, and the organizing committee to adhere to the <a href="https://www.acm.org/special-interest-groups/volunteer-resources/acm-conflict-of-interest-policy" target="_blank">ACM’s Conflict of Interest Policy </a> and the <a href="https://www.acm.org/code-of-ethics" target="_blank">ACM’s Code of Ethics and Professional Conduct</a>. </p>
          </div>
      </div>

    </section>

    <!--==========================
    Keynote Section
    ============================-->
    <section id="keynote" class="wow fadeInUp">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Keynote</h2>

		     <p style="text-align: center;"><img src="https://scholar.googleusercontent.com/citations?view_op=view_photo&user=D4NJsXEIh1cJ&citpid=15" class="img-rounded" alt="Carlos Castillo"></p>

			 <p style="text-align: center;"><strong><a href="http://chato.cl/research/" target="_blank">Carlos Castillo</a> <br> Universitat Pompeu Fabra (Spain)</strong></p>

			 <p><strong>Title</strong>: Fairness and Transparency in Ranking</p>

			 <p><strong>Abstract</strong>: Ranking in Information Retrieval (IR) has been traditionally evaluated from the perspective of the relevance of search engine results to people searching for information, i.e., the extent to which the system provides "the right information, to the right people, in the right way, at the right time." However, people in current IR systems are not only the ones issuing search queries, but increasingly they are also the ones being searched. This raises several new problems in IR that have been addressed in recent research, particularly with respect to fairness/non-discrimination, accountability, and transparency.

			 <p><strong>Short Bio</strong>: Carlos Castillo is a Distinguished Research Professor at Universitat Pompeu Fabra in Barcelona, where he leads the Web Science and Social Computing research group. He is a web miner with a background on information retrieval, and has been influential in the areas of crisis informatics, web content quality and credibility, and adversarial web search. He is a prolific, highly cited researcher who has co-authored over 80 publications in top-tier international conferences and journals, receiving a test-of-time award, four best paper awards, and two best student paper awards. His works include a book on Big Crisis Data, as well as monographs on Information and Influence Propagation, and Adversarial Web Search.

			 <p><strong>Slides</strong>: <a href="./asset/keynote_slides.pdf" target="_blank">Download here</a></p>

        </div>
      </div>

    </section>

    <!--==========================
    Program Section
    ============================-->
    <section id="program" class="wow fadeInUp section-with-bg">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Program</h2>

          <p>
              Due to the ongoing worldwide COVID-19 situation, the BIAS@ECIR2021 workshop will take place <strong>online</strong> on <strong>April 1, 2021, 09:00-16:30, CEST</strong>.
              To participate, you need to register to the ECIR conference. Once registered, you will receive by e-mail further details on how to join the workshop.
          </p>


			<div style="margin: 10px auto 30px auto; width: 50%;">
				<table class="table">
					<thead>
					<tr>
						<th scope="col" class="time" style="min-width: 100px;">Timing</th>
						<th scope="col">Content</th>
					</tr>
					</thead>
					<tbody>
					<tr>
						<th scope="row" class="time"><strong>09:00 09:05</strong></th>
						<td><strong>Welcome Message</strong></td>
					</tr>
					<tr>
						<th scope="row" class="time"><strong>09:05 10:00</strong></th>
						<td>
							<strong>Keynote Talk</strong> on <strong>Fairness and Transparency in Ranking</strong> by <strong>Carlos Castillo</strong> (Universitat Pompeu Fabra)
						</td>
					</tr>
					<tr>
						<th scope="row" class="time"><strong>10:00 10:30</strong></th>
						<td>
                            <div style="margin-bottom: 9px;"><strong>Paper Session I (short introduction)</strong></div>
                            <ul>
                                <li><strong>10:00 - 10:15 (12 mins + 3 mins Q&A)</strong></br> Towards Fairness-Aware Ranking by Defining Latent Groups Using Inferred Features </br> Yunhe Feng; Daniel Saelid; Ke Li; Ruoyuan Gao; Chirag Shah </li>
                                <li><strong>10:15 - 10:30 (12 mins + 3 mins Q&A)</strong></br> Media Bias Everywhere? A Vision for Dealing with the Manipulation of Public Opinion </br> Michael Färber; Frederic Bartscherer </li>
                        </td>
					</tr>
					<tr>
						<th scope="row" class="time"><strong>10:30 11:00</strong></th>
						<td><strong>Coffee Break</strong></td>
					</tr>
					<tr>
						<th scope="row" class="time"><strong>11:00 13:00</strong></th>
						<td>
                            <div style="margin-bottom: 9px;"><strong>Paper Session II (short introduction)</strong></div>
                            <ul>
                                <li><strong>11:05 - 11:20 (12 mins + 3 mins Q&A)</strong></br> Preliminary Experiments on the Stability of Fairness-Aware Techniques</br> Toshihiro Kamishima; Shotaro Akaho; Yukino Baba; Hisashi Kashima </li>
                                <li><strong>11:20 - 11:40 (15 mins + 5 mins Q&A)</strong></br> Detecting Race and Gender Bias in Visual Representation of AI on Web Search Engines </br> Mykola Makhortykh; Aleksandra Urman; Roberto Ulloa </li>
                                <li><strong>11:40 - 12:00 (15 mins + 5 mins Q&A)</strong></br> Equality of Opportunity in Ranking: A Fair-Distributive Model </br> Elena Beretta; Antonio Vetrò; Bruno Lepri; Juan Carlos De Martin </li>
                                <li><strong>12:00 - 12:20 (15 mins + 5 mins Q&A)</strong></br> Incentives for Item Duplication under Fair Ranking Policies</br> Giorgio Maria Di Nunzio; Alessandro Fabris; Gianmaria Silvello; Gian Antonio Susto  </li>
                                <li><strong>12:20 - 12:40 (15 mins + 5 mins Q&A)</strong></br> Users' Perception of Search-Engine Biases and Satisfaction </br> Bin Han; Chirag Shah; Daniel Saelid </li>
                                <li><strong>12:40 - 13:00 (15 mins + 5 mins Q&A)</strong></br> Quantification of the Impact of Popularity Bias in Multi-Stakeholder and Time-Aware Environment </br> Javier Ruiz; María Ignacia Sánchez; Francisco Guíñez </li>
                            </ul>
                        </td>
					</tr>
					<tr>
						<th scope="row" class="time"><strong>13:00 14:10</strong></th>
						<td><strong>Lunch Break</strong></td>
					</tr>
					<tr>
						<th scope="row" class="time"><strong>14:10 16:15</strong></th>
						<td>
                            <div style="margin-bottom: 9px;"><strong>Paper Session III (short introduction)</strong></div>
                            <ul>
                                <li><strong>14:15 - 14:35 (15 mins + 5 mins Q&A)</strong></br> When is a Recommendation Model Wrong? A Model-Agnostic Tree-Based Approach to Detecting Biases in Recommendations</br> Joanna Misztal-Radecka; Bipin Indurkhya </li>
                                <li><strong>14:35 - 14:55 (15 mins + 5 mins Q&A)</strong></br> Evaluating Video Recommendation Bias on YouTube </br> Baris Kirdemir; Maryetta Morris; Esther Mead; Muhammad Nihal Hussein; Nitin Agarwal </li>
                                <li><strong>14:55 - 15:15 (15 mins + 5 mins Q&A)</strong></br> An Information-Theoretic Measure for Enabling Category Exemptions with an Application to Filter Bubbles </br>Bowen Wu; Chenyu Jiang; Sanghamitra Dutta; Pulkit Grover   </li>
                                <li><strong>15:15 - 15:35 (15 mins + 5 mins Q&A)</strong></br> Perception-Aware Bias Detection for Query Suggestions</br> Fabian Haak; Philipp Schaer  </li>
                                <li><strong>15:35 - 15:55 (15 mins + 5 mins Q&A)</strong></br> Crucial Challenges in Large-Scale Black Box Analyses </br> Tobias Krafft; Martin Reber; Roman Krafft; Anna Couturier; Katharina Zweig </li>
                                <li><strong>15:55 - 16:15 (15 mins + 5 mins Q&A)</strong></br> New Metrics for Offline Evaluation of Content-based TV Recommendation Systems </br> Luísa Simões; Vaibhav Shah; João Silva; Nelson Rodrigues; Nuno Leite; Nuno Lopes </li>
                            </ul>
                        </td>
					</tr>
					<tr>
						<th scope="row" class="time"><strong>16:15 16:30</strong></th>
						<td><strong>Discussion and Concluding Remarks</strong></td>
					</tr>
					</tbody>
				</table>
			</div>





        </div>
      </div>

    </section>

    <!--==========================
    Committee Section
    ============================-->
    <section id="committee" class="wow fadeInUp">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Committee</h2>
          <p><strong>Workshop Chairs</strong></p>
          <ul>
            <li><a href="https://www.ludovicoboratto.com/" target="_blank">Ludovico Boratto</a>, Eurecat - Centre Tecnológic de Catalunya (Spain)</li>
            <li><a href="https://www.unitelmasapienza.it/it/contenuti/personale/stefano-faralli" target="_blank">Stefano Faralli</a>, Unitelma Sapienza University of Rome (Italy)</li>
            <li><a href="https://www.mirkomarras.com/" target="_blank">Mirko Marras</a>, École Polytechnique Fédérale de Lausanne EPFL (Switzerland)</li>
            <li><a href="https://scholar.google.com/citations?user=uTyaicMAAAAJ&hl=en" target="_blank">Giovanni Stilo</a>, University of L’Aquila (Italy)</li>
          </ul>
          <p><strong>Program Committee</strong></p>
          <ul>
            <li>Himan Abdollahpouri, Northwestern University (United States)</li>
            <li>Luca Maria Aiello, Nokia Bell Labs (United Kingdom)</li>
            <li>Mehwish	Alam, FIZ-Karlsruhe & KIT (Germany)</li>
            <li>Marcelo Gabriel	Armentano, ISISTAN Research Institute CONICET-UNCPBA (Argentina)</li>
            <li>Alejandro Bellogin, Universidad Autonoma de Madrid (Spain)</li>
            <li>Bettina	Berendt, Katholieke Universiteit Leuven (Belgium)</li>
            <li>Glencora Borradaile, Oregon State University (United States)</li>
            <li>Federica Cena, University of Turin (Italy)</li>
            <li>Jeffrey Chen, RMIT University (Australia)</li>
            <li>Pasquale De Meo, Vrije Universiteit Amsterdam (The Netherlands)</li>
            <li>Sarah Dean, University of California Berkeley (United States)</li>
            <li>Danilo Dessì, FIZ-Karlsruhe & KIT (Germany)</li>
            <li>Michael	Ekstrand, Boise State University (United States)</li>
            <li>Francesco Fabbri, Universitat Pompeu Fabra (Spain)</li>
            <li>Jean Garcia-Gathright, Spotify (United States)</li>
            <li>Aniko Hannak, Northeaster University (United States)</li>
            <li>Nina Grgic-Hlaca, MPI-SWS (Germany)</li>
            <li>Genet Asefa	Gesese, FIZ-Karlsruhe (Germany)</li>
            <li>Toshihiro Kamishima, AIST (Japan)</li>
            <li>Martha Larson, Radboud University and TU Delft (The Netherlands)</li>
            <li>Aonghus	Lawlor, University College Dublin (Ireland)</li>
            <li>Sandy Mayson, University of Georgia (United States)</li>
            <li>Rishabh	Mehrotra, Spotify (United Kingdom)</li>
            <li>Brent Mittelstadt, University of Oxford (United Kingdom)</li>
            <li>Cataldo	Musto, University of Bari (Italy)</li>
            <li>Panagiotis Papadakos, Information Systems Laboratory - FORTH-ICS (Greece)</li>
            <li>Mykola Pechenizkiy, Eindhoven University of Technology (The Netherlands)</li>
            <li>Simone Paolo Ponzetto, University of Mannheim (Germany)</li>
            <li>Elissa Redmiles, MPI-SWS (Germany)</li>
            <li>Flora D. Salim, RMIT University (Australia)</li>
            <li>Ruofei Shen, Facebook (United States)</li>
            <li>Damiano Spina, RMIT University (Australia)</li>
            <li>Antonela Tommasel, ISISTAN Research Institute CONICET-UNCPBA (Argentina)</li>
            <li>Joris van Hoboken, University of Amsterdam (The Netherlands)</li>
            <li>Kyle Williams, Microsoft (United States)</li>
            <li>Eva	Zangerle, University of Innsbruck (Austria)</li>
            <li>Markus Zanker, Free University of Bozen-Bolzano (Italy)</li>
            <li>Meike Zehlike, MPI-SWS(Germany)</li>
            <li>Dong Zhou, Hunan University of Science and Technology (China)</li>
            <li>Arkaitz	Zubiaga, Queen Mary University of London (United Kingdom)</li>
          </ul>
          </div>
      </div>

    </section>

    <!--==========================
    Attending Section
    ============================-->
    <section id="attending" class="wow fadeInUp section-with-bg">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Registration</h2>
          <ul>
            <li><a href="https://www.ecir2021.eu/registration/" target="_blank">Registration Portal</a></li>
          </ul>
        </div>
      </div>

    </section>

    <!--==========================
    Past Editions Section
    ============================-->
    <section id="editions" class="wow fadeInUp">

      <div class="container-fluid">
        <div class="section-header">
			<h2>Past Editions</h2>
			<p>We also invite you to check out previous editions of our similar workshops:</p>
			<ul>
				<li><a href="http://bias.disim.univaq.it/" target="_blank">1st International Workshop on Algorithmic Bias in Search and Recommendation (Bias@ECIR2020)</a></li>
			</ul>
        </div>
      </div>

    </section>

    <!--==========================
    Contacts Section
    ============================-->
    <section id="contacts" class="wow fadeInUp section-with-bg">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Contacts</h2>
          <p>For general enquiries on the workshop, please send an email to <strong>ludovico.boratto@acm.org</strong>, <strong>stefano.faralli@unitelmasapienza.it</strong>,
             <strong>mirko.marras@epfl.ch</strong>, and <strong>giovanni.stilo@univaq.it</strong>.</p>
        </div>
      </div>

    </section>


  </main>

  <a href="#" class="back-to-top"><i class="fa fa-angle-up"></i></a>

  <!-- JavaScript Libraries -->
  <script src="lib/jquery/jquery.min.js"></script>
  <script src="lib/jquery/jquery-migrate.min.js"></script>
  <script src="lib/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="lib/easing/easing.min.js"></script>
  <script src="lib/superfish/hoverIntent.js"></script>
  <script src="lib/superfish/superfish.min.js"></script>
  <script src="lib/wow/wow.min.js"></script>
  <script src="lib/venobox/venobox.min.js"></script>
  <script src="lib/owlcarousel/owl.carousel.min.js"></script>

  <!-- Contact Form JavaScript File -->
  <script src="contactform/contactform.js"></script>

  <!-- Template Main Javascript File -->
  <script src="js/main.js"></script>
</body>

</html>
